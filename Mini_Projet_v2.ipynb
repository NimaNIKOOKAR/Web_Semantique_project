{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b8f4c1f",
   "metadata": {},
   "source": [
    "# Projet : Extraction et Recommandation de films et séries avec rdflib et SPARQL\n",
    "\n",
    "## Objectif\n",
    "L’objectif de ce mini-projet est l’extraction des données de la base de données DBPedia en utilisant le langage de requêtes SPARQL afin d'alimenter la base de données de séries que vous avez créé au premier TP, l’analyse de ces données et la recommandation de séries et de films."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af27ca9",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "Vous allez créer un système de recommandation de séries/films basé sur des données RDF qui stockent des informations sur les films, les utilisateurs et leurs préférences cinématographiques.\n",
    "\n",
    "Les étapes du projet sont comme suit :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83e1264",
   "metadata": {},
   "source": [
    "## 1.  Extraction des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46de8783",
   "metadata": {},
   "source": [
    "a)  Vous utiliserez Rdflib pour accéder aux données et vous effectuerez des requêtes SPARQL pour les extraire. Vous êtes libres dans le choix et la taille des données que vous allez extraire. Le jeu de données doit néanmoins être représentatif pour pouvoir fournir des recommandations précises. \n",
    "    \n",
    "   - Les données à extraire : \n",
    "       - Films : Chaque film a un titre, un réalisateur, une année de sortie, un genre (e.g. : action, comédie, science-fiction), un résumé, une liste d'acteurs principaux, une durée, une évaluation du film, etc.\n",
    "       - Réalisateur : Chaque réalisateur a un nom, une biographie et une liste de films qu'il a réalisés.\n",
    "       - Acteurs : Chaque acteur a un nom, une biographie et une liste de films dans lesquels il a joué.\n",
    "       - Genres :  Chaque genre a un nom et une description.\n",
    "       - Utilisateurs : chaque utilisateur a un identifiant et des préférences cinématographiques (acteurs préférés, genres préférés, etc).\n",
    "       - Évaluations : Elle est décrite par l'identifiant de l'utilisateur qui a donné l'évaluation, identifiant du film évalué la note attribuée au film, Commentaire ou avis sur le film.\n",
    "\n",
    "   - Liens entre les entités : \n",
    "\n",
    "        - Les films sont associés à leurs acteurs, réalisateurs et genres.\n",
    "        - Les utilisateurs sont associés aux films qu'ils ont évalués.\n",
    "        - Les utilisateurs peuvent être liés entre eux en fonction de leurs préférences cinématographiques similaires.\n",
    "\n",
    "   b)  Transformer les données en triplets RDF :  Vous allez transformer ces résultats en triplets RDF avant de les ajouter à votre graphe RDF existant. \n",
    "  \n",
    "  c) Ajouter les données au graphe existant : Utilisez la méthode g.add() de votre graphe RDF, que vous avez créé au premier TP, pour ajouter les triplets RDF représentant les données DBpedia que vous avez transformées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c4ca788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "from rdflib.namespace import RDF, RDFS, XSD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Create our custom namespace for film data\n",
    "EX = Namespace(\"http://example.org/film#\")\n",
    "\n",
    "# =============================================================================\n",
    "# 1. DATA EXTRACTION - SPARQL + RDF\n",
    "# =============================================================================\n",
    "def extract_data_sparql(endpoint, query):\n",
    "    \"\"\"\n",
    "    Extracts data from a SPARQL endpoint and returns JSON bindings.\n",
    "    \"\"\"\n",
    "    sparql = SPARQLWrapper(endpoint)\n",
    "    sparql.setQuery(query)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results[\"results\"][\"bindings\"]\n",
    "\n",
    "def build_rdf_graph(data):\n",
    "    \"\"\"\n",
    "    Builds and returns an RDF graph from the JSON results of a SPARQL query.\n",
    "    \"\"\"\n",
    "    g = Graph()\n",
    "    g.bind(\"ex\", EX)\n",
    "    \n",
    "    for row in data:\n",
    "        film_uri = URIRef(row[\"film\"][\"value\"])\n",
    "        \n",
    "        # Title\n",
    "        if \"title\" in row:\n",
    "            g.add((film_uri, RDFS.label, Literal(row[\"title\"][\"value\"], datatype=XSD.string)))\n",
    "        # Director\n",
    "        if \"director\" in row:\n",
    "            director_uri = URIRef(row[\"director\"][\"value\"])\n",
    "            g.add((film_uri, EX.director, director_uri))\n",
    "        # Actor\n",
    "        if \"actor\" in row:\n",
    "            actor_uri = URIRef(row[\"actor\"][\"value\"])\n",
    "            g.add((film_uri, EX.actor, actor_uri))\n",
    "        # Genre\n",
    "        if \"genre\" in row:\n",
    "            genre_uri = URIRef(row[\"genre\"][\"value\"])\n",
    "            g.add((film_uri, EX.genre, genre_uri))\n",
    "        # Release Date\n",
    "        if \"releaseDate\" in row:\n",
    "            g.add((film_uri, EX.releaseDate, Literal(row[\"releaseDate\"][\"value\"], datatype=XSD.date)))\n",
    "    return g\n",
    "\n",
    "# Example DBpedia Query\n",
    "endpoint = \"http://dbpedia.org/sparql\"\n",
    "film_query = \"\"\"\n",
    "SELECT ?film ?title ?genre ?director ?releaseDate ?actor\n",
    "WHERE {\n",
    "  ?film rdf:type dbo:Film.\n",
    "  ?film rdfs:label ?title.\n",
    "  FILTER (lang(?title) = 'en').\n",
    "  OPTIONAL { ?film dbo:genre ?genre. }\n",
    "  OPTIONAL { ?film dbo:director ?director. }\n",
    "  OPTIONAL { ?film dbo:releaseDate ?releaseDate. }\n",
    "  OPTIONAL { ?film dbo:starring ?actor. }\n",
    "}\n",
    "LIMIT 700\n",
    "\"\"\"\n",
    "# Extract and build the graph\n",
    "data = extract_data_sparql(endpoint, film_query)\n",
    "graph = build_rdf_graph(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22c45ed",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdd6862",
   "metadata": {},
   "source": [
    "## 2. Prétraitement des données   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e511a8",
   "metadata": {},
   "source": [
    "Nettoyez et traitez les données extraites pour supprimer les doublons, gérer les valeurs manquantes et normaliser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7c849f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2. DATA PREPROCESSING\n",
    "# =============================================================================\n",
    "def preprocess_graph(g):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes the RDF graph by removing duplicates,\n",
    "    handling empty literals, and normalizing text to lowercase (if not date).\n",
    "    \"\"\"\n",
    "    cleaned = Graph()\n",
    "    cleaned.bind(\"ex\", EX)\n",
    "    \n",
    "    for s, p, o in g:\n",
    "        # Skip empty literals\n",
    "        if isinstance(o, Literal) and not str(o).strip():\n",
    "            continue\n",
    "        \n",
    "        # Normalize string literals (exclude date or numeric)\n",
    "        if isinstance(o, Literal) and o.datatype != XSD.date:\n",
    "            val = str(o).strip().lower()\n",
    "            cleaned.add((s, p, Literal(val)))\n",
    "        else:\n",
    "            cleaned.add((s, p, o))\n",
    "    return cleaned\n",
    "\n",
    "graph = preprocess_graph(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46be1e6e",
   "metadata": {},
   "source": [
    "## 3. Analyse exploratoire des données "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c1c996",
   "metadata": {},
   "source": [
    "- Créer des graphiques permettant de visualiser la distribution des films et séries dans votre base de données.\n",
    "- Créer un graphique pour montrer les films et les séries les mieux notés\n",
    "- Créer un nuage de points pour représenter la relation entre les caractéristiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "abeb0297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. (Optional) EXPLORATORY DATA ANALYSIS\n",
    "# =============================================================================\n",
    "def visualize_data(g):\n",
    "    \"\"\"\n",
    "    Visualize genre distribution and release year distribution.\n",
    "    \"\"\"\n",
    "    # Genre distribution\n",
    "    genres = []\n",
    "    for s, p, o in g.triples((None, EX.genre, None)):\n",
    "        genres.append(o.split(\"/\")[-1])\n",
    "    \n",
    "    if genres:\n",
    "        counter = Counter(genres)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.bar(counter.keys(), counter.values(), color='skyblue')\n",
    "        plt.title(\"Genre Distribution\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No genre data to visualize.\")\n",
    "    \n",
    "    # Release year distribution\n",
    "    years = []\n",
    "    for s, p, o in g.triples((None, EX.releaseDate, None)):\n",
    "        try:\n",
    "            year = int(str(o)[:4])  # parse the first 4 chars as year\n",
    "            years.append(year)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if years:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.hist(years, bins=10, edgecolor=\"black\", color='lightgreen')\n",
    "        plt.title(\"Release Year Distribution\")\n",
    "        plt.xlabel(\"Year\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No valid releaseDate data to visualize.\")\n",
    "\n",
    "def visualize_graph(g):\n",
    "    \"\"\"\n",
    "    Visualize the RDF graph using NetworkX.\n",
    "    \"\"\"\n",
    "    nx_graph = nx.Graph()\n",
    "    for s, p, o in g:\n",
    "        nx_graph.add_edge(str(s), str(o), label=str(p))\n",
    "    \n",
    "    if nx_graph.number_of_nodes() == 0:\n",
    "        print(\"No data to visualize.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    pos = nx.spring_layout(nx_graph, k=0.5)\n",
    "    nx.draw(nx_graph, pos, with_labels=True, node_size=500, font_size=8, node_color=\"lightblue\")\n",
    "    edge_labels = nx.get_edge_attributes(nx_graph, 'label')\n",
    "    nx.draw_networkx_edge_labels(nx_graph, pos, edge_labels=edge_labels, font_size=7)\n",
    "    plt.title(\"RDF Graph Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "# Optional EDA\n",
    "# visualize_data(graph)\n",
    "# visualize_graph(graph)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fbe967",
   "metadata": {},
   "source": [
    "## 4. Système de Recommandation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6623413d",
   "metadata": {},
   "source": [
    "a) Utiliser SPARQL pour interroger le graphe RDF afin de créer un système de recommandation de films et/ou séries. Vous pouvez envisager différentes approches de recommandation, telles que la recommandation collaborative (en fonction des évaluations d'utilisateurs similaires) ou la recommandation basée sur le contenu (en fonction des genres, des acteurs, etc.) ou la recommandation basée sur les connaissances\n",
    "\n",
    "b) Utiliser une IA (ChatGPT ou tout autre) pour répondre à cette question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "149b554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 4. CONTENT-BASED & AI-BASED RECOMMENDATIONS\n",
    "#    Using multiple features: actors, directors, genres\n",
    "# =============================================================================\n",
    "\n",
    "# --- 4a) FEATURE-BASED (CONTENT-BASED) APPROACH ---\n",
    "def recommend_feature_based(g, user_prefs):\n",
    "    \"\"\"\n",
    "    Returns a list of films that match the user's preferred actors, directors, or genres.\n",
    "    user_prefs = {\n",
    "      \"genres\": [...],\n",
    "      \"directors\": [...],\n",
    "      \"actors\": [...]\n",
    "    }\n",
    "    \"\"\"\n",
    "    pref_genres = [pg.lower() for pg in user_prefs.get(\"genres\", [])]\n",
    "    pref_directors = [pd.lower() for pd in user_prefs.get(\"directors\", [])]\n",
    "    pref_actors = [pa.lower() for pa in user_prefs.get(\"actors\", [])]\n",
    "\n",
    "    recommended = set()\n",
    "\n",
    "    for film in g.subjects(None, None):\n",
    "        # Gather film's features\n",
    "        film_genres = [str(o).lower() for o in g.objects(film, EX.genre)]\n",
    "        film_directors = [str(o).lower() for o in g.objects(film, EX.director)]\n",
    "        film_actors = [str(o).lower() for o in g.objects(film, EX.actor)]\n",
    "        \n",
    "        # Check matches\n",
    "        match_genre = any(pg in fg for fg in film_genres for pg in pref_genres)\n",
    "        match_director = any(pd in fd for fd in film_directors for pd in pref_directors)\n",
    "        match_actor = any(pa in fa for fa in film_actors for pa in pref_actors)\n",
    "\n",
    "        # If the film matches ANY of the user's preferences, add it\n",
    "        if match_genre or match_director or match_actor:\n",
    "            recommended.add(str(film))\n",
    "\n",
    "    return list(recommended)\n",
    "\n",
    "# --- 4b) AI-BASED (MULTI-FEATURE) APPROACH ---\n",
    "def ai_recommend_multifeature(g, user_prefs):\n",
    "    \"\"\"\n",
    "    AI-based recommendation that merges user preferences (genres, directors, actors)\n",
    "    into a single text. Each film is also described by its title + actors + directors + genres.\n",
    "    We use CountVectorizer + cosine similarity to rank films.\n",
    "    \"\"\"\n",
    "    # Combine user preferences into a single text string\n",
    "    user_genres = [g_.lower() for g_ in user_prefs.get(\"genres\", [])]\n",
    "    user_directors = [d_.lower() for d_ in user_prefs.get(\"directors\", [])]\n",
    "    user_actors = [a_.lower() for a_ in user_prefs.get(\"actors\", [])]\n",
    "\n",
    "    # e.g. \"comedy horror spielberg atom_egoyan tom_hanks sandra_bullock\"\n",
    "    user_info = \" \".join(user_genres + user_directors + user_actors).strip()\n",
    "    if not user_info:\n",
    "        print(\"No user preferences found. Returning empty recommendations.\")\n",
    "        return []\n",
    "\n",
    "    # Build extended text for each film\n",
    "    film_texts = {}\n",
    "    for film in g.subjects(None, None):\n",
    "        # Title\n",
    "        labels = list(g.objects(film, RDFS.label))\n",
    "        title_text = labels[0].lower() if labels else \"\"\n",
    "\n",
    "        # Actors\n",
    "        film_actors = [str(o).lower() for o in g.objects(film, EX.actor)]\n",
    "        # Directors\n",
    "        film_directors = [str(o).lower() for o in g.objects(film, EX.director)]\n",
    "        # Genres\n",
    "        film_genres = [str(o).lower() for o in g.objects(film, EX.genre)]\n",
    "\n",
    "        # Combine\n",
    "        # e.g. \"cadet kelly tom hanks steven spielberg horror film\"\n",
    "        film_pieces = []\n",
    "        if title_text:\n",
    "            film_pieces.append(title_text)\n",
    "        if film_actors:\n",
    "            film_pieces.append(\" \".join(film_actors))\n",
    "        if film_directors:\n",
    "            film_pieces.append(\" \".join(film_directors))\n",
    "        if film_genres:\n",
    "            film_pieces.append(\" \".join(film_genres))\n",
    "\n",
    "        if film_pieces:\n",
    "            film_uri_str = str(film)\n",
    "            film_texts[film_uri_str] = \" \".join(film_pieces)\n",
    "\n",
    "    if not film_texts:\n",
    "        print(\"No film data for AI-based recommendations.\")\n",
    "        return []\n",
    "\n",
    "    # Vectorize user text vs. film text\n",
    "    all_film_descriptions = list(film_texts.values())\n",
    "    vectorizer = CountVectorizer()\n",
    "    film_matrix = vectorizer.fit_transform(all_film_descriptions)\n",
    "    user_vec = vectorizer.transform([user_info])\n",
    "\n",
    "    # Cosine similarity\n",
    "    sims = cosine_similarity(user_vec, film_matrix)[0]  # shape: [num_films]\n",
    "    sorted_indices = np.argsort(sims)[::-1]\n",
    "\n",
    "    film_uris = list(film_texts.keys())\n",
    "    top_10 = [film_uris[i] for i in sorted_indices[:10]]\n",
    "    return top_10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6be6488",
   "metadata": {},
   "source": [
    "## 5. Calcul des Recommandations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb6cb54",
   "metadata": {},
   "source": [
    "a) Utiliser SPARQL pour générer des requêtes de recommandation en fonction des préférences de l'utilisateur. Vous pouvez également utiliser des algorithmes d'apprentissage automatique pour améliorer les recommandations.\n",
    "\n",
    "b) Utiliser une IA pour répondre à cette question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e11cd2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 5. EVALUATION: MAP@k, NDCG@k\n",
    "# =============================================================================\n",
    "def evaluate_recommendations(ground_truth, predicted):\n",
    "    \"\"\"\n",
    "    Evaluates recommendations using MAP@k and NDCG@k.\n",
    "    \n",
    "    ground_truth: list of URIs the user actually likes (favorite films).\n",
    "    predicted: list of recommended film URIs.\n",
    "    \"\"\"\n",
    "    if not predicted:\n",
    "        return {\"MAP@k\": 0.0, \"NDCG@k\": 0.0}\n",
    "    \n",
    "    k = len(predicted)\n",
    "    \n",
    "    # MAP@k\n",
    "    average_precision = 0.0\n",
    "    relevant_found = 0\n",
    "    for i, item in enumerate(predicted[:k]):\n",
    "        if item in ground_truth:\n",
    "            relevant_found += 1\n",
    "            average_precision += relevant_found / (i + 1)\n",
    "    map_k = average_precision / len(ground_truth) if ground_truth else 0.0\n",
    "\n",
    "    # NDCG@k\n",
    "    y_true = [1 if it in ground_truth else 0 for it in predicted[:k]]\n",
    "    y_score = [1 / (idx + 1) for idx in range(k)]\n",
    "    ndcg_k = ndcg_score([y_true], [y_score])\n",
    "\n",
    "    return {\"MAP@k\": map_k, \"NDCG@k\": ndcg_k}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baeb1585",
   "metadata": {},
   "source": [
    "## 6. Évaluation  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493d7060",
   "metadata": {},
   "source": [
    "a) Évaluez la qualité de vos recommandations en utilisant des mesures telles que  MAP@k (Mean Average Precision at k) ou NDCG@k (Normalized Discounted Cumulative Gain at k)\n",
    "\n",
    "b) Comparer les recommandations que vous avez obtenues par rapport à celles générées par l'IA que vous aurez utilisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3b825d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature-Based Content Recommendations: ['http://dbpedia.org/resource/Cadet_Kelly', 'http://dbpedia.org/resource/California_Typewriter', 'http://dbpedia.org/resource/Calendar_(1993_film)', 'http://dbpedia.org/resource/Cabin_by_the_Lake', 'http://dbpedia.org/resource/Call_Me_Claus']\n",
      "AI-Based Multi-Feature Recommendations: ['http://dbpedia.org/resource/Calendar_(1993_film)', 'http://dbpedia.org/resource/California_Typewriter', 'http://dbpedia.org/resource/Call_Girls_of_Rome', 'http://dbpedia.org/resource/Calamity_Anne,_Heroine', 'http://dbpedia.org/resource/Caitlin_Plays_Herself', 'http://dbpedia.org/resource/Call_Jane', 'http://dbpedia.org/resource/California_Straight_Ahead!', 'http://dbpedia.org/resource/Calendar_Girls_(2015_film)', \"http://dbpedia.org/resource/Calamity_Anne's_Love_Affair\", 'http://dbpedia.org/resource/Cagliostro_(1929_film)']\n",
      "Feature-Based Content Evaluation: {'MAP@k': 0.75, 'NDCG@k': np.float64(0.8772153153380493)}\n",
      "AI-Based Evaluation: {'MAP@k': 0.0, 'NDCG@k': np.float64(0.0)}\n",
      "Feature-based content approach performed better (MAP@k).\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. COMPARE THE TWO APPROACHES: EXAMPLE USAGE\n",
    "# =============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    user_prefs = {\n",
    "        \"genres\": [\"comedy\", \"horror\"],\n",
    "        \"directors\": [\"spielberg\", \"atom_egoyan\"],\n",
    "        \"actors\": [\"tom_hanks\", \"sandra_bullock\"],\n",
    "        \"favorite_films\": [\n",
    "            # Make sure at least one of these URIs is in the recommended sets for nonzero scores\n",
    "            \"http://dbpedia.org/resource/Cadet_Kelly\",  \n",
    "            \"http://dbpedia.org/resource/Cabin_by_the_Lake\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    # --- Approach 1: Feature-based Content ---\n",
    "    cb_recs = recommend_feature_based(graph, user_prefs)\n",
    "    print(\"Feature-Based Content Recommendations:\", cb_recs)\n",
    "    \n",
    "    # --- Approach 2: AI-based multi-feature ---\n",
    "    ai_recs = ai_recommend_multifeature(graph, user_prefs)\n",
    "    print(\"AI-Based Multi-Feature Recommendations:\", ai_recs)\n",
    "    \n",
    "    # --- Evaluate ---\n",
    "    ground_truth = user_prefs[\"favorite_films\"]\n",
    "    cb_scores = evaluate_recommendations(ground_truth, cb_recs)\n",
    "    ai_scores = evaluate_recommendations(ground_truth, ai_recs)\n",
    "\n",
    "    print(\"Feature-Based Content Evaluation:\", cb_scores)\n",
    "    print(\"AI-Based Evaluation:\", ai_scores)\n",
    "\n",
    "    if cb_scores[\"MAP@k\"] > ai_scores[\"MAP@k\"]:\n",
    "        print(\"Feature-based content approach performed better (MAP@k).\")\n",
    "    elif cb_scores[\"MAP@k\"] < ai_scores[\"MAP@k\"]:\n",
    "        print(\"AI-based multi-feature approach performed better (MAP@k).\")\n",
    "    else:\n",
    "        print(\"They performed the same (MAP@k).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8b3fce",
   "metadata": {},
   "source": [
    "## 7. Rapport "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7b0a0c",
   "metadata": {},
   "source": [
    "Vous allez rédiger un rapport de 5 pages max décrivant la modélisation RDF, les requêtes SPARQL, l'algorithme de recommandation et les résultats de l'évaluation. Vous spécifierez votre utilisation de l'IA dans le cadre de ce projet et ce que vous en pensez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb8e27f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
